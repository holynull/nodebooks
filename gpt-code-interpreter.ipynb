{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd9d98f",
   "metadata": {},
   "source": [
    "安装langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc4df44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.0.231-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in ./.venv/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.18-cp311-cp311-macosx_10_9_x86_64.whl (2.0 MB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.8.4-cp311-cp311-macosx_10_9_x86_64.whl (355 kB)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
      "  Using cached dataclasses_json-0.5.9-py3-none-any.whl (26 kB)\n",
      "Collecting langchainplus-sdk<0.0.21,>=0.0.20 (from langchain)\n",
      "  Using cached langchainplus_sdk-0.0.20-py3-none-any.whl (25 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4 (from langchain)\n",
      "  Using cached numexpr-2.8.4-cp311-cp311-macosx_10_9_x86_64.whl (99 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.25.1-cp311-cp311-macosx_10_9_x86_64.whl (20.0 MB)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
      "  Using cached openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "Collecting pydantic<2,>=1 (from langchain)\n",
      "  Using cached pydantic-1.10.11-cp311-cp311-macosx_10_9_x86_64.whl (2.8 MB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting charset-normalizer<4.0,>=2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached charset_normalizer-3.2.0-cp311-cp311-macosx_10_9_x86_64.whl (125 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.4-cp311-cp311-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.2-cp311-cp311-macosx_10_9_x86_64.whl (64 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.0-cp311-cp311-macosx_10_9_x86_64.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Using cached marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting typing-extensions>=4.2.0 (from pydantic<2,>=1->langchain)\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-2.0.2-cp311-cp311-macosx_10_9_universal2.whl (243 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tenacity, numpy, mypy-extensions, multidict, marshmallow, greenlet, frozenlist, charset-normalizer, certifi, async-timeout, yarl, typing-inspect, SQLAlchemy, requests, pydantic, numexpr, marshmallow-enum, aiosignal, openapi-schema-pydantic, langchainplus-sdk, dataclasses-json, aiohttp, langchain\n",
      "Successfully installed SQLAlchemy-2.0.18 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 certifi-2023.5.7 charset-normalizer-3.2.0 dataclasses-json-0.5.9 frozenlist-1.4.0 greenlet-2.0.2 langchain-0.0.231 langchainplus-sdk-0.0.20 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 numexpr-2.8.4 numpy-1.25.1 openapi-schema-pydantic-1.2.4 pydantic-1.10.11 requests-2.31.0 tenacity-8.2.2 typing-extensions-4.7.1 typing-inspect-0.9.0 urllib3-2.0.3 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain\n",
    "pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb887a2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain, PromptTemplate\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "# if getattr(sys, 'frozen', False):\n",
    "#     script_location = pathlib.Path(sys.executable).parent.resolve()\n",
    "# else:\n",
    "#     script_location = pathlib.Path(__file__).parent.resolve()\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "prompt_template = \"\"\"Please use Python to implement the following requirements. Only generate code blocks in Markdown format without requiring any additional content. As follows:\n",
    "```python\n",
    "print(\"Hello world!\")\n",
    "```\n",
    "Requirements:\n",
    "{user_inputs}\n",
    "\n",
    "\"\"\"\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.9,\n",
    "    verbose=True,\n",
    ")\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(prompt_template),\n",
    "    verbose=True,\n",
    ")\n",
    "user_inputs = input(\"Input your requirements: \")\n",
    "res = llm_chain.predict(user_inputs=user_inputs)\n",
    "print(res)\n",
    "code_sta = res.find(\"```python\")\n",
    "code_end = res.rfind(\"```\")\n",
    "if code_sta != -1 and code_end != -1:\n",
    "    code = res[(code_sta + 9) : code_end]\n",
    "    try:\n",
    "        exec(code)\n",
    "    except Exception as err:\n",
    "        print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca064508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
